{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poster Statistics Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Difference in file size after Unstructured pruning + Huffman encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = []\n",
    "for k in range(9):\n",
    "    input_files.append('../software/files_pruned/weight_pruned_kij'+str(k)+'.txt')\n",
    "\n",
    "output_file = 'original_weights.txt'\n",
    "\n",
    "with open(output_file, 'w') as merged_file:\n",
    "    for input_file_name in input_files:\n",
    "        line_number = 1\n",
    "        # Open each input file for reading\n",
    "        with open(input_file_name, 'r') as input_file:\n",
    "                for line in input_file:\n",
    "                    # If the current line number is less than or equal to 3, skip the line\n",
    "                    if line_number <= 3:\n",
    "                        line_number += 1\n",
    "                        continue\n",
    "        \n",
    "                    # If the current line number is greater than 3, write the line to the output file\n",
    "                    merged_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_weights.txt is 59.68% smaller than encoded_weights.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace these with the file paths you want to compare\n",
    "file1_path = 'original_weights.txt'\n",
    "file2_path = 'encoded_weights.txt'\n",
    "\n",
    "# Get the size of file1\n",
    "file1_size = os.path.getsize(file1_path)\n",
    "\n",
    "# Get the size of file2\n",
    "file2_size = os.path.getsize(file2_path)\n",
    "\n",
    "# Calculate the difference in sizes\n",
    "difference = file1_size - file2_size\n",
    "\n",
    "percentage_decrease = (difference / file1_size) * 100\n",
    "print(f\"{file1_path} is {percentage_decrease:.2f}% smaller than {file2_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_activations.txt is 39.13% smaller than encoded_activations.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace these with the file paths you want to compare\n",
    "file1_path = 'original_activations.txt'\n",
    "file2_path = 'encoded_activations.txt'\n",
    "\n",
    "# Get the size of file1\n",
    "file1_size = os.path.getsize(file1_path)\n",
    "\n",
    "# Get the size of file2\n",
    "file2_size = os.path.getsize(file2_path)\n",
    "\n",
    "# Calculate the difference in sizes\n",
    "difference = file1_size - file2_size\n",
    "\n",
    "percentage_decrease = (difference / file1_size) * 100\n",
    "print(f\"{file1_path} is {percentage_decrease:.2f}% smaller than {file2_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Difference in file size after Unstructured pruning + Run-length Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RLC_weights.txt is 63.93% smaller than original_weights.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace these with the file paths you want to compare\n",
    "file1_path = 'original_weights.txt'\n",
    "file2_path = 'RLC_weights.txt'\n",
    "\n",
    "# Get the size of file1\n",
    "file1_size = os.path.getsize(file1_path)\n",
    "\n",
    "# Get the size of file2\n",
    "file2_size = os.path.getsize(file2_path)\n",
    "\n",
    "# Calculate the difference in sizes\n",
    "difference = file1_size - file2_size\n",
    "\n",
    "percentage_decrease = (difference / file1_size) * 100\n",
    "print(f\"{file2_path} is {percentage_decrease:.2f}% smaller than {file1_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RLC_activations.txt is 13.88% smaller than original_activations.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace these with the file paths you want to compare\n",
    "file1_path = 'original_activations.txt'\n",
    "file2_path = 'RLC_activations.txt'\n",
    "\n",
    "# Get the size of file1\n",
    "file1_size = os.path.getsize(file1_path)\n",
    "\n",
    "# Get the size of file2\n",
    "file2_size = os.path.getsize(file2_path)\n",
    "\n",
    "# Calculate the difference in sizes\n",
    "difference = file1_size - file2_size\n",
    "\n",
    "percentage_decrease = (difference / file1_size) * 100\n",
    "print(f\"{file2_path} is {percentage_decrease:.2f}% smaller than {file1_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Difference in file size after Unstructured pruning + Compressed Sparse Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSC_weights.txt is 30.47% smaller than original_weights.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace these with the file paths you want to compare\n",
    "file1_path = 'original_weights.txt'\n",
    "file2_path = 'CSC_weights.txt'\n",
    "file3_path = 'CSC_length.txt'\n",
    "\n",
    "\n",
    "# Get the size of file1\n",
    "file1_size = os.path.getsize(file1_path)\n",
    "\n",
    "# Get the size of file2\n",
    "file2_size = os.path.getsize(file2_path)\n",
    "\n",
    "file3_size = os.path.getsize(file3_path)\n",
    "\n",
    "# Calculate the difference in sizes\n",
    "difference = file1_size - file2_size - file3_size\n",
    "\n",
    "percentage_decrease = (difference / file1_size) * 100\n",
    "print(f\"{file2_path} is {percentage_decrease:.2f}% smaller than {file1_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSC_activations.txt is -66.66% smaller than original_activations.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace these with the file paths you want to compare\n",
    "file1_path = 'original_activations.txt'\n",
    "file2_path = 'CSC_activations.txt'\n",
    "file3_path = 'CSC_length_act.txt'\n",
    "\n",
    "\n",
    "# Get the size of file1\n",
    "file1_size = os.path.getsize(file1_path)\n",
    "\n",
    "# Get the size of file2\n",
    "file2_size = os.path.getsize(file2_path)\n",
    "\n",
    "file3_size = os.path.getsize(file3_path)\n",
    "\n",
    "# Calculate the difference in sizes\n",
    "difference = file1_size - file2_size - file3_size\n",
    "\n",
    "percentage_decrease = (difference / file1_size) * 100\n",
    "print(f\"{file2_path} is {percentage_decrease:.2f}% smaller than {file1_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a Huffman Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000000000000000001000000000000\\n', '00000000000000000000000000000000\\n', '00000000000000000000000000000000\\n', '00000000000000000000000000000000\\n']\n",
      "['00000000000000000000000000000000\\n', '00000000000000000000000000000000\\n', '00000000000000000001000000000000\\n', '00000000000000000000000000000000\\n']\n",
      "['11000000110000000000000000000110\\n', '00000000000000010000000000000000\\n', '00000000110100101101000011100001\\n', '00000000001011000000000000100000\\n']\n",
      "['11010000000000000001000000100000\\n', '00000000000000000000000000000000\\n', '00010000000000100000000000001101\\n', '00000000001011100001000000000000\\n']\n",
      "['00000000000000000000000000000001\\n', '00000000000000000000000000000000\\n', '00000000000100000000000000000000\\n', '00000000000100000000000000000000\\n']\n",
      "['00000000000000000000000000000000\\n', '00000000000000000000000000000000\\n', '00000000000000000000000000000000\\n', '00000000000000000000000000001110\\n']\n",
      "['00000000000000000001000000000000\\n', '00000000000000110000000000000000\\n', '00110000000000110000000011100000\\n', '00000000000000010000000000000000\\n']\n",
      "['00000000000000000000000000010000\\n', '00000000000000000000000000000000\\n', '00000000000000010000000000000000\\n', '00000000000000000000000000010000\\n']\n",
      "['00000000000000000000000001010111\\n', '00000000111001110101000000000000\\n', '01110000000000000100000010010011\\n', '00100000010101000000000001111010\\n']\n",
      "['01000000000011000101000001110000\\n', '00000000000000000000000000000000\\n', '01110000000000101101000001000000\\n', '11010000011100000100000000000111\\n']\n",
      "['00000000000000001101000000010011\\n', '00000000000000000000000000000000\\n', '00010000000000000000000000000000\\n', '00000000000000000000000000010000\\n']\n",
      "['00010000000000000010000000011110\\n', '00000000000000000000000000000000\\n', '00100000000000000000000000000000\\n', '00000000010000000000000000000001\\n']\n",
      "['00000000000000000000000000000000\\n', '00000000000000000000000000000000\\n', '00000000000000000000000000000000\\n', '00000000000000000000000000000000\\n']\n",
      "['00000000000000000000000000000000\\n', '00000000000000000000000000000000\\n', '00000000000000000000000000000000\\n', '00000000000000000000000000000000\\n']\n",
      "['00000000000000000000000000000000\\n', '11010000000001000000000000000000\\n', '00110000000100000100000000000000\\n', '11010000000000110000000000000000\\n']\n",
      "['00100000110000000110000000000000\\n', '00000000000000000000000000000000\\n', '00110000000000001011000001000001\\n', '00000000001000010000000000000001\\n']\n",
      "['00000000000000000000000000000000\\n', '00000000000000000001000000000000\\n', '00000000000000000000000000000000\\n', '00000000000000000000000000100000\\n']\n",
      "['00000000000000000001000000000000\\n', '00000000000000000000000000000000\\n', '00000000000000001101000000000001\\n', '00000000000000000000000011100000\\n']\n",
      "[None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "with open('original_weights.txt', 'r') as file:\n",
    "    hex_values = []  # Initialize an empty list to store the hexadecimal values\n",
    "\n",
    "    for line in file:\n",
    "        # Remove any leading/trailing whitespace and split the line into 4-bit chunks\n",
    "        binary_chunks = [line[i:i+4] for i in range(0, len(line), 4)]\n",
    "        \n",
    "        # Convert each binary chunk to hexadecimal and concatenate them\n",
    "        hex_value = ''.join([hex(int(chunk, 2))[2:] for chunk in binary_chunks])\n",
    "        \n",
    "        # Append the combined hexadecimal value to the list\n",
    "        hex_values.append(hex_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
