{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e59d9d81",
   "metadata": {},
   "source": [
    "## Train VGG16 with quantization-aware training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b4ea4",
   "metadata": {},
   "source": [
    "### 1. Train for 4-bit input activation and 4-bit weight to achieve >90% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"VGG16_quant\"\n",
    "model = VGG16_quant()\n",
    "# print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a822a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is from the website\n",
    "\n",
    "lr = 4e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 300\n",
    "best_prec = 0\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "# weight decay: for regularization to prevent overfitting\n",
    "\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "    \n",
    "fdir = 'result/'+str(model_name)\n",
    "\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9134/10000 (91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/VGG16_quant/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "287d5f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG_quant(\n",
       "  (features): Sequential(\n",
       "    (0): QuantConv2d(\n",
       "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): QuantConv2d(\n",
       "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): QuantConv2d(\n",
       "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): QuantConv2d(\n",
       "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): QuantConv2d(\n",
       "      128, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (15): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): QuantConv2d(\n",
       "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): QuantConv2d(\n",
       "      8, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (23): QuantConv2d(\n",
       "      256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (24): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): QuantConv2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (27): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (28): ReLU(inplace=True)\n",
       "    (29): QuantConv2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (33): QuantConv2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): QuantConv2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): QuantConv2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (41): ReLU(inplace=True)\n",
       "    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -th layer prehooked\n",
      "7 -th layer prehooked\n",
      "12 -th layer prehooked\n",
      "16 -th layer prehooked\n",
      "21 -th layer prehooked\n",
      "25 -th layer prehooked\n",
      "28 -th layer prehooked\n",
      "33 -th layer prehooked\n",
      "37 -th layer prehooked\n",
      "41 -th layer prehooked\n",
      "46 -th layer prehooked\n",
      "50 -th layer prehooked\n",
      "54 -th layer prehooked\n"
     ]
    }
   ],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2., -2., -2.],\n",
      "          [-2., -2., -2.],\n",
      "          [-3., -2., -2.]],\n",
      "\n",
      "         [[-3., -3., -2.],\n",
      "          [-3., -2., -2.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-2., -1., -1.],\n",
      "          [-2., -1., -2.],\n",
      "          [-2., -2., -2.]],\n",
      "\n",
      "         [[-2., -2., -1.],\n",
      "          [-2., -2., -1.],\n",
      "          [-3., -2., -2.]],\n",
      "\n",
      "         [[-2., -2., -2.],\n",
      "          [-2., -2., -2.],\n",
      "          [-2., -2., -2.]],\n",
      "\n",
      "         [[-1., -1., -1.],\n",
      "          [-2., -1., -1.],\n",
      "          [-2., -2., -2.]],\n",
      "\n",
      "         [[-3., -1., -1.],\n",
      "          [-3., -2., -2.],\n",
      "          [-2., -2., -2.]],\n",
      "\n",
      "         [[-2., -2., -2.],\n",
      "          [-2., -3., -2.],\n",
      "          [-2., -2., -2.]]],\n",
      "\n",
      "\n",
      "        [[[-0., -0.,  0.],\n",
      "          [-2., -1., -1.],\n",
      "          [-1., -1., -1.]],\n",
      "\n",
      "         [[-7.,  7., -7.],\n",
      "          [ 7.,  7.,  7.],\n",
      "          [ 7., -0., -7.]],\n",
      "\n",
      "         [[ 7.,  7.,  7.],\n",
      "          [ 7.,  7., -7.],\n",
      "          [-2.,  7., -7.]],\n",
      "\n",
      "         [[ 7.,  7., -7.],\n",
      "          [ 7.,  7.,  7.],\n",
      "          [-7.,  3., -2.]],\n",
      "\n",
      "         [[-7., -7., -2.],\n",
      "          [-7., -7.,  7.],\n",
      "          [ 7., -7.,  7.]],\n",
      "\n",
      "         [[-1.,  7.,  2.],\n",
      "          [ 7.,  7.,  7.],\n",
      "          [-7.,  2., -0.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.],\n",
      "          [-1., -1., -1.],\n",
      "          [-2., -2., -2.]],\n",
      "\n",
      "         [[ 7.,  1., -1.],\n",
      "          [-7., -7., -7.],\n",
      "          [ 7., -7.,  7.]]],\n",
      "\n",
      "\n",
      "        [[[-2., -1., -0.],\n",
      "          [-1., -1., -1.],\n",
      "          [-1., -1., -1.]],\n",
      "\n",
      "         [[-3.,  7.,  7.],\n",
      "          [-7.,  7.,  7.],\n",
      "          [ 1., -7., -1.]],\n",
      "\n",
      "         [[-2., -7., -7.],\n",
      "          [ 7.,  7.,  7.],\n",
      "          [-0.,  7.,  7.]],\n",
      "\n",
      "         [[-7.,  7., -7.],\n",
      "          [-1.,  7.,  7.],\n",
      "          [-7.,  7., -7.]],\n",
      "\n",
      "         [[ 7., -7.,  7.],\n",
      "          [ 7.,  7.,  7.],\n",
      "          [ 7.,  7., -7.]],\n",
      "\n",
      "         [[ 1., -7., -1.],\n",
      "          [ 7., -7., -7.],\n",
      "          [ 1.,  7., -1.]],\n",
      "\n",
      "         [[-2., -2., -1.],\n",
      "          [-2., -2., -1.],\n",
      "          [-2., -2., -1.]],\n",
      "\n",
      "         [[ 7., -7., -7.],\n",
      "          [-7., -7., -1.],\n",
      "          [-7., -1.,  3.]]],\n",
      "\n",
      "\n",
      "        [[[ 0., -1., -1.],\n",
      "          [ 1.,  0., -1.],\n",
      "          [-0., -0., -1.]],\n",
      "\n",
      "         [[-7.,  7.,  7.],\n",
      "          [ 7.,  7.,  7.],\n",
      "          [-7.,  7., -1.]],\n",
      "\n",
      "         [[ 7., -7.,  0.],\n",
      "          [-7., -7., -7.],\n",
      "          [-1., -7.,  7.]],\n",
      "\n",
      "         [[-2.,  3., -1.],\n",
      "          [ 7.,  7.,  7.],\n",
      "          [-1.,  7., -7.]],\n",
      "\n",
      "         [[ 7.,  7.,  7.],\n",
      "          [-1.,  0.,  7.],\n",
      "          [-7., -7.,  1.]],\n",
      "\n",
      "         [[ 1., -4., -7.],\n",
      "          [-3.,  7., -3.],\n",
      "          [ 7.,  7., -7.]],\n",
      "\n",
      "         [[-0., -0., -1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [ 0., -1., -1.]],\n",
      "\n",
      "         [[-1.,  7., -7.],\n",
      "          [ 7.,  7., -7.],\n",
      "          [-7.,  7.,  7.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -2.],\n",
      "          [-2., -2., -2.],\n",
      "          [-1., -1., -1.]],\n",
      "\n",
      "         [[ 7.,  7., -7.],\n",
      "          [ 3.,  7., -7.],\n",
      "          [-7., -7., -0.]],\n",
      "\n",
      "         [[-7.,  7.,  1.],\n",
      "          [-7., -7.,  7.],\n",
      "          [-2.,  2., -2.]],\n",
      "\n",
      "         [[ 0., -7., -2.],\n",
      "          [-7., -7., -1.],\n",
      "          [ 7.,  7., -0.]],\n",
      "\n",
      "         [[ 5., -7.,  7.],\n",
      "          [ 7.,  7.,  0.],\n",
      "          [ 7.,  7., -7.]],\n",
      "\n",
      "         [[-0.,  7.,  7.],\n",
      "          [ 7.,  7.,  7.],\n",
      "          [ 3.,  7.,  3.]],\n",
      "\n",
      "         [[-1., -1., -1.],\n",
      "          [-2., -1., -2.],\n",
      "          [-1., -1., -1.]],\n",
      "\n",
      "         [[-7.,  7.,  7.],\n",
      "          [-7.,  7., -7.],\n",
      "          [-1., -7., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-2., -2., -1.],\n",
      "          [-2., -2., -1.],\n",
      "          [-3., -2., -2.]],\n",
      "\n",
      "         [[-7., -7.,  7.],\n",
      "          [ 7.,  7.,  7.],\n",
      "          [-2.,  7., -1.]],\n",
      "\n",
      "         [[-7.,  7., -7.],\n",
      "          [ 7.,  7., -7.],\n",
      "          [ 7.,  7.,  4.]],\n",
      "\n",
      "         [[ 0., -7.,  7.],\n",
      "          [ 1., -7., -7.],\n",
      "          [-7., -1., -7.]],\n",
      "\n",
      "         [[ 7., -7.,  2.],\n",
      "          [-2.,  7.,  7.],\n",
      "          [-7.,  7., -1.]],\n",
      "\n",
      "         [[ 5.,  7., -7.],\n",
      "          [ 1.,  1.,  7.],\n",
      "          [-7., -7., -0.]],\n",
      "\n",
      "         [[-0., -0., -1.],\n",
      "          [-2., -2., -1.],\n",
      "          [-3., -2., -2.]],\n",
      "\n",
      "         [[-0.,  7., -0.],\n",
      "          [ 7.,  7.,  7.],\n",
      "          [ 2.,  7., -7.]]],\n",
      "\n",
      "\n",
      "        [[[-0., -1., -1.],\n",
      "          [-1., -1., -1.],\n",
      "          [-1., -2., -2.]],\n",
      "\n",
      "         [[-7., -1.,  7.],\n",
      "          [-7., -7., -7.],\n",
      "          [ 7., -7., -7.]],\n",
      "\n",
      "         [[ 2., -2.,  7.],\n",
      "          [-7.,  7., -7.],\n",
      "          [ 7., -3., -2.]],\n",
      "\n",
      "         [[-1.,  7.,  1.],\n",
      "          [ 7.,  7.,  2.],\n",
      "          [ 2.,  7., -7.]],\n",
      "\n",
      "         [[-7.,  7., -7.],\n",
      "          [ 7.,  7.,  7.],\n",
      "          [ 7.,  7., -7.]],\n",
      "\n",
      "         [[-7.,  7., -7.],\n",
      "          [-2.,  7.,  7.],\n",
      "          [-1., -7.,  7.]],\n",
      "\n",
      "         [[-1., -1., -1.],\n",
      "          [-2., -1., -2.],\n",
      "          [-2., -2., -2.]],\n",
      "\n",
      "         [[ 7.,  7., -1.],\n",
      "          [ 4.,  7.,  7.],\n",
      "          [-7.,  0., -7.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -2., -3.],\n",
      "          [-2., -3., -3.],\n",
      "          [-2., -3., -3.]],\n",
      "\n",
      "         [[-1., -2., -2.],\n",
      "          [-2., -3., -3.],\n",
      "          [-1., -2., -3.]],\n",
      "\n",
      "         [[-2., -2., -2.],\n",
      "          [-2., -2., -2.],\n",
      "          [-3., -2., -2.]],\n",
      "\n",
      "         [[-1., -2., -2.],\n",
      "          [-1., -2., -2.],\n",
      "          [-1., -2., -3.]],\n",
      "\n",
      "         [[-2., -2., -1.],\n",
      "          [-2., -1., -2.],\n",
      "          [-2., -2., -2.]],\n",
      "\n",
      "         [[-1., -1., -1.],\n",
      "          [-2., -2., -3.],\n",
      "          [-2., -2., -3.]],\n",
      "\n",
      "         [[-3., -3., -2.],\n",
      "          [-3., -3., -3.],\n",
      "          [-2., -3., -3.]],\n",
      "\n",
      "         [[-2., -2., -3.],\n",
      "          [-2., -2., -2.],\n",
      "          [-2., -1., -2.]]]], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# The convolutional layer with a input channel number of 8 and a output channel number of 8 \n",
    "# has a index of 17 in the model.features\n",
    "weight_q = model.features[17].weight_q\n",
    "w_alpha = model.features[17].weight_quant.wgt_alpha\n",
    "w_bit = 4\n",
    "\n",
    "weight_int = weight_q / (w_alpha / (2**(w_bit-1)-1))\n",
    "print(weight_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "interior-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 4.0000,  2.0000,  6.0000,  ...,  8.0000,  3.0000,  0.0000],\n",
      "          [ 7.0000,  7.0000,  4.0000,  ...,  1.0000,  0.0000,  1.0000],\n",
      "          [ 6.0000,  3.0000,  3.0000,  ...,  0.0000,  0.0000,  5.0000],\n",
      "          ...,\n",
      "          [ 8.0000,  4.0000,  6.0000,  ...,  6.0000,  5.0000,  2.0000],\n",
      "          [ 5.0000,  4.0000,  2.0000,  ...,  5.0000,  5.0000,  3.0000],\n",
      "          [ 8.0000,  4.0000,  4.0000,  ...,  4.0000,  4.0000,  5.0000]],\n",
      "\n",
      "         [[ 5.0000,  4.0000,  0.0000,  ...,  1.0000,  4.0000,  6.0000],\n",
      "          [ 9.0000,  8.0000,  0.0000,  ...,  7.0000, 11.0000, 10.0000],\n",
      "          [12.0000,  6.0000,  1.0000,  ...,  6.0000, 11.0000, 10.0000],\n",
      "          ...,\n",
      "          [11.0000,  5.0000,  1.0000,  ...,  1.0000,  5.0000,  6.0000],\n",
      "          [13.0000,  5.0000,  4.0000,  ...,  3.0000,  3.0000,  6.0000],\n",
      "          [11.0000,  3.0000,  3.0000,  ...,  4.0000,  4.0000,  8.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0000,  7.0000,  6.0000,  ...,  0.0000,  5.0000,  9.0000],\n",
      "          [ 2.0000,  4.0000,  5.0000,  ...,  0.0000,  3.0000, 13.0000],\n",
      "          [ 4.0000,  2.0000,  8.0000,  ...,  3.0000,  3.0000, 12.0000],\n",
      "          ...,\n",
      "          [ 3.0000,  5.0000,  4.0000,  ...,  4.0000,  3.0000,  3.0000],\n",
      "          [ 1.0000,  5.0000,  3.0000,  ...,  4.0000,  2.0000,  1.0000],\n",
      "          [ 1.0000,  3.0000,  7.0000,  ...,  5.0000,  5.0000,  4.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  2.0000,  2.0000,  ...,  0.0000,  1.0000,  7.0000],\n",
      "          [ 4.0000,  3.0000,  7.0000,  ...,  2.0000,  1.0000,  7.0000],\n",
      "          [10.0000,  6.0000,  9.0000,  ...,  5.0000,  6.0000,  7.0000],\n",
      "          ...,\n",
      "          [ 5.0000,  7.0000,  0.0000,  ...,  0.0000,  0.0000,  3.0000],\n",
      "          [ 1.0000,  9.0000,  0.0000,  ...,  0.0000,  2.0000,  5.0000],\n",
      "          [ 0.0000,  3.0000,  2.0000,  ...,  3.0000,  5.0000,  6.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 6.0000,  2.0000,  4.0000,  ...,  5.0000,  3.0000,  3.0000],\n",
      "          [ 9.0000,  2.0000,  2.0000,  ...,  8.0000,  3.0000,  1.0000],\n",
      "          [ 9.0000,  5.0000,  6.0000,  ...,  8.0000,  8.0000,  5.0000],\n",
      "          ...,\n",
      "          [ 3.0000,  6.0000,  6.0000,  ..., 12.0000,  8.0000,  1.0000],\n",
      "          [ 1.0000,  6.0000,  7.0000,  ...,  9.0000,  0.0000,  0.0000],\n",
      "          [ 3.0000,  4.0000,  8.0000,  ...,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "         [[ 9.0000,  5.0000,  4.0000,  ...,  4.0000,  4.0000,  4.0000],\n",
      "          [ 5.0000,  5.0000,  3.0000,  ...,  1.0000,  3.0000,  5.0000],\n",
      "          [ 4.0000,  7.0000,  4.0000,  ...,  0.0000,  4.0000,  8.0000],\n",
      "          ...,\n",
      "          [ 4.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  9.0000],\n",
      "          [ 8.0000,  0.0000,  6.0000,  ...,  0.0000,  4.0000, 10.0000],\n",
      "          [10.0000,  3.0000,  7.0000,  ...,  4.0000,  8.0000,  8.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.0000,  8.0000,  9.0000,  ..., 10.0000,  9.0000,  7.0000],\n",
      "          [ 4.0000,  5.0000,  4.0000,  ...,  4.0000,  8.0000,  6.0000],\n",
      "          [ 4.0000,  6.0000,  5.0000,  ...,  3.0000,  5.0000,  6.0000],\n",
      "          ...,\n",
      "          [ 6.0000,  5.0000,  5.0000,  ...,  3.0000,  3.0000,  0.0000],\n",
      "          [ 5.0000,  9.0000,  5.0000,  ...,  3.0000,  0.0000,  0.0000],\n",
      "          [ 3.0000,  7.0000,  3.0000,  ...,  2.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  6.0000,  1.0000,  3.0000],\n",
      "          [ 0.0000,  2.0000,  4.0000,  ...,  6.0000,  0.0000,  2.0000],\n",
      "          [ 3.0000,  6.0000,  7.0000,  ...,  5.0000,  3.0000,  2.0000],\n",
      "          ...,\n",
      "          [ 2.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  1.0000],\n",
      "          [ 2.0000,  0.0000,  2.0000,  ...,  0.0000,  0.0000,  2.0000],\n",
      "          [ 3.0000,  0.0000,  0.0000,  ...,  0.0000,  3.0000,  4.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 4.0000,  3.0000,  4.0000,  ...,  5.0000,  4.0000,  5.0000],\n",
      "          [11.0000,  7.0000,  8.0000,  ...,  7.0000,  7.0000,  7.0000],\n",
      "          [ 9.0000,  7.0000,  8.0000,  ...,  4.0000,  3.0000,  5.0000],\n",
      "          ...,\n",
      "          [ 7.0000,  4.0000,  5.0000,  ...,  8.0000,  4.0000,  5.0000],\n",
      "          [ 8.0000,  5.0000,  8.0000,  ...,  4.0000,  1.0000,  4.0000],\n",
      "          [ 6.0000,  5.0000,  5.0000,  ...,  5.0000,  5.0000,  5.0000]],\n",
      "\n",
      "         [[ 8.0000,  3.0000,  4.0000,  ...,  5.0000,  6.0000,  4.0000],\n",
      "          [ 6.0000,  0.0000,  3.0000,  ...,  3.0000,  4.0000,  4.0000],\n",
      "          [ 3.0000,  0.0000,  1.0000,  ...,  1.0000,  1.0000,  3.0000],\n",
      "          ...,\n",
      "          [ 6.0000,  1.0000,  1.0000,  ...,  2.0000,  1.0000, 11.0000],\n",
      "          [ 5.0000,  0.0000,  0.0000,  ...,  1.0000,  2.0000, 11.0000],\n",
      "          [ 5.0000,  4.0000,  2.0000,  ...,  5.0000,  5.0000,  9.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.0000,  7.0000,  8.0000,  ...,  9.0000,  9.0000,  7.0000],\n",
      "          [ 2.0000,  1.0000,  2.0000,  ...,  3.0000,  6.0000,  8.0000],\n",
      "          [ 4.0000,  1.0000,  2.0000,  ...,  0.0000,  0.0000,  9.0000],\n",
      "          ...,\n",
      "          [ 6.0000,  1.0000,  2.0000,  ...,  6.0000,  3.0000,  2.0000],\n",
      "          [ 4.0000,  3.0000,  5.0000,  ...,  2.0000,  3.0000,  2.0000],\n",
      "          [ 5.0000,  2.0000,  4.0000,  ...,  5.0000,  5.0000,  4.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  3.0000,  ...,  4.0000,  1.0000,  4.0000],\n",
      "          [ 4.0000,  4.0000,  6.0000,  ...,  2.0000,  2.0000,  5.0000],\n",
      "          [ 6.0000,  7.0000,  5.0000,  ...,  1.0000,  6.0000,  7.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  3.0000,  3.0000,  ...,  0.0000,  3.0000,  5.0000],\n",
      "          [ 2.0000,  4.0000,  3.0000,  ...,  2.0000,  6.0000,  6.0000],\n",
      "          [ 3.0000,  2.0000,  1.0000,  ...,  5.0000,  5.0000,  6.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 4.0000,  4.0000,  3.0000,  ...,  5.0000,  4.0000,  5.0000],\n",
      "          [ 6.0000,  6.0000,  3.0000,  ...,  8.0000,  2.0000,  4.0000],\n",
      "          [ 5.0000,  3.0000,  2.0000,  ...,  5.0000,  5.0000,  5.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  3.0000,  ...,  9.0000,  4.0000,  0.0000],\n",
      "          [ 4.0000,  0.0000,  0.0000,  ...,  4.0000,  5.0000,  0.0000],\n",
      "          [ 8.0000,  4.0000,  1.0000,  ...,  0.0000,  2.0000,  5.0000]],\n",
      "\n",
      "         [[ 7.0000,  6.0000,  5.0000,  ...,  4.0000,  4.0000,  7.0000],\n",
      "          [ 9.0000,  7.0000,  6.0000,  ...,  9.0000,  7.0000,  7.0000],\n",
      "          [ 8.0000,  3.0000,  3.0000,  ...,  4.0000,  6.0000,  4.0000],\n",
      "          ...,\n",
      "          [ 8.0000,  5.0000,  0.0000,  ...,  3.0000,  5.0000,  4.0000],\n",
      "          [12.0000,  6.0000,  3.0000,  ...,  1.0000,  2.0000,  8.0000],\n",
      "          [10.0000, 10.0000,  5.0000,  ...,  1.0000,  0.0000,  7.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.0000,  6.0000,  5.0000,  ...,  8.0000,  6.0000,  1.0000],\n",
      "          [ 4.0000,  1.0000,  2.0000,  ...,  4.0000,  2.0000,  0.0000],\n",
      "          [ 4.0000,  1.0000,  1.0000,  ...,  0.0000,  0.0000,  3.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  1.0000,  3.0000,  ...,  3.0000,  6.0000,  3.0000],\n",
      "          [ 1.0000,  0.0000,  2.0000,  ...,  1.0000,  4.0000,  9.0000],\n",
      "          [ 4.0000,  0.0000,  0.0000,  ...,  4.0000,  9.0000, 11.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 5.0000,  4.0000,  1.0000,  ...,  7.0000,  3.0000,  1.0000],\n",
      "          [ 6.0000,  3.0000,  0.0000,  ...,  8.0000,  6.0000,  2.0000],\n",
      "          [ 3.0000,  3.0000,  1.0000,  ...,  6.0000,  5.0000,  2.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  0.0000,  ...,  6.0000,  0.0000,  1.0000],\n",
      "          [ 0.0000,  0.0000,  1.0000,  ...,  5.0000,  0.0000,  3.0000],\n",
      "          [ 4.0000,  0.0000,  0.0000,  ...,  0.0000,  3.0000,  4.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 5.0000,  2.0000,  8.0000,  ...,  7.0000,  3.0000,  2.0000],\n",
      "          [ 4.0000,  0.0000,  3.0000,  ..., 12.0000,  8.0000,  6.0000],\n",
      "          [ 7.0000,  4.0000,  1.0000,  ...,  9.0000,  8.0000,  8.0000],\n",
      "          ...,\n",
      "          [ 6.0000,  1.0000,  6.0000,  ...,  4.0000,  5.0000,  7.0000],\n",
      "          [ 7.0000,  4.0000,  5.0000,  ...,  5.0000,  5.0000,  5.0000],\n",
      "          [ 7.0000,  7.0000,  7.0000,  ...,  5.0000,  5.0000,  6.0000]],\n",
      "\n",
      "         [[ 9.0000,  2.0000,  0.0000,  ...,  5.0000,  5.0000,  1.0000],\n",
      "          [10.0000,  2.0000,  6.0000,  ...,  0.0000,  3.0000,  0.0000],\n",
      "          [10.0000,  7.0000, 11.0000,  ...,  0.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 9.0000,  2.0000,  4.0000,  ...,  2.0000,  1.0000,  5.0000],\n",
      "          [11.0000,  5.0000,  5.0000,  ...,  4.0000,  4.0000,  4.0000],\n",
      "          [ 8.0000,  5.0000,  8.0000,  ...,  4.0000,  5.0000,  6.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0000,  7.0000,  3.0000,  ...,  5.0000,  5.0000,  5.0000],\n",
      "          [ 3.0000,  1.0000,  3.0000,  ...,  4.0000,  3.0000, 11.0000],\n",
      "          [ 2.0000,  0.0000,  1.0000,  ...,  3.0000,  1.0000,  9.0000],\n",
      "          ...,\n",
      "          [ 3.0000,  0.0000,  1.0000,  ...,  2.0000,  3.0000,  3.0000],\n",
      "          [ 2.0000,  0.0000,  1.0000,  ...,  1.0000,  2.0000,  2.0000],\n",
      "          [ 2.0000,  1.0000,  2.0000,  ...,  3.0000,  3.0000,  4.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  1.0000,  ...,  7.0000,  3.0000,  4.0000],\n",
      "          [ 0.0000,  1.0000,  4.0000,  ...,  9.0000,  4.0000,  6.0000],\n",
      "          [ 0.0000,  0.0000,  3.0000,  ...,  2.0000,  3.0000,  5.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  3.0000,  5.0000,  ...,  3.0000,  4.0000,  5.0000],\n",
      "          [ 0.0000,  1.0000,  2.0000,  ...,  1.0000,  2.0000,  4.0000],\n",
      "          [ 0.0000,  3.0000,  5.0000,  ...,  4.0000,  4.0000,  5.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 5.0000,  3.0000,  0.0000,  ...,  3.0000,  1.0000,  3.0000],\n",
      "          [ 4.0000,  5.0000,  2.0000,  ...,  5.0000,  5.0000,  4.0000],\n",
      "          [ 4.0000,  6.0000,  6.0000,  ...,  1.0000,  4.0000,  3.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  4.0000,  5.0000,  ...,  3.0000,  1.0000,  3.0000],\n",
      "          [ 3.0000,  0.0000,  3.0000,  ...,  4.0000,  0.0000,  2.0000],\n",
      "          [ 3.0000,  3.0000,  5.0000,  ...,  0.0000,  2.0000,  4.0000]],\n",
      "\n",
      "         [[ 3.0000,  3.0000,  5.0000,  ...,  3.0000,  3.0000,  5.0000],\n",
      "          [ 1.0000,  4.0000,  9.0000,  ...,  4.0000,  4.0000,  5.0000],\n",
      "          [ 0.0000,  4.0000,  9.0000,  ...,  1.0000,  5.0000,  6.0000],\n",
      "          ...,\n",
      "          [ 7.0000,  8.0000,  6.0000,  ...,  1.0000,  4.0000,  7.0000],\n",
      "          [ 4.0000,  0.0000,  2.0000,  ...,  3.0000,  7.0000,  7.0000],\n",
      "          [ 2.0000,  0.0000,  2.0000,  ...,  7.0000, 11.0000,  9.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.0000,  5.0000,  5.0000,  ...,  6.0000,  7.0000,  8.0000],\n",
      "          [ 3.0000,  0.0000,  2.0000,  ...,  3.0000,  3.0000,  6.0000],\n",
      "          [ 5.0000,  2.0000,  1.0000,  ...,  1.0000,  0.0000,  5.0000],\n",
      "          ...,\n",
      "          [ 4.0000,  9.0000,  4.0000,  ...,  4.0000,  2.0000,  2.0000],\n",
      "          [ 3.0000,  5.0000,  6.0000,  ...,  4.0000,  2.0000,  4.0000],\n",
      "          [ 4.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  5.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 5.0000,  5.0000,  5.0000,  ...,  2.0000,  2.0000,  6.0000],\n",
      "          [ 3.0000,  4.0000,  5.0000,  ...,  1.0000,  0.0000,  4.0000],\n",
      "          [ 5.0000,  8.0000, 10.0000,  ...,  5.0000,  2.0000,  3.0000],\n",
      "          ...,\n",
      "          [ 8.0000,  8.0000,  4.0000,  ...,  2.0000,  0.0000,  4.0000],\n",
      "          [ 0.0000,  6.0000,  8.0000,  ...,  0.0000,  0.0000,  4.0000],\n",
      "          [ 0.0000,  3.0000,  6.0000,  ...,  1.0000,  3.0000,  4.0000]]]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "act = save_output.outputs[5][0]\n",
    "act_alpha  = model.features[17].act_alpha\n",
    "act_bit = 4\n",
    "act_quant_fn = act_quantization(act_bit)\n",
    "\n",
    "act_q = act_quant_fn(act, act_alpha)\n",
    "\n",
    "act_int = act_q / (act_alpha / (2**act_bit-1))\n",
    "print(act_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "victorian-above",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ -4.8176,  -7.2585,  -6.8303,  ...,  -5.2886,  -5.9524,  -4.5606],\n",
      "          [ -8.3291, -12.4615, -10.8128,  ...,  -8.6931,  -9.2926,  -6.9587],\n",
      "          [ -9.3568, -14.0888, -11.4337,  ...,  -8.8001,  -9.6138,  -7.2585],\n",
      "          ...,\n",
      "          [ -6.9587, -10.9841,  -9.2283,  ...,  -7.7081,  -8.8001,  -6.2950],\n",
      "          [ -7.6439, -11.9048,  -9.6994,  ...,  -7.9222,  -9.8921,  -7.3441],\n",
      "          [ -4.7533,  -7.7081,  -6.0809,  ...,  -4.8818,  -6.4020,  -4.9889]],\n",
      "\n",
      "         [[  2.3339,  11.6478,   5.6526,  ...,   4.8604,   6.7232,   4.7962],\n",
      "          [  3.1047,  10.7057,   6.6161,  ...,  -0.4711,   4.3037,   9.9563],\n",
      "          [  6.2950,   7.6653,   1.3489,  ...,   2.3767,   7.5797,   9.6352],\n",
      "          ...,\n",
      "          [  7.5368,   4.4108,   5.7811,  ...,   7.3441,   7.1300,   5.9310],\n",
      "          [ 10.6629,   8.4789,   3.8112,  ...,   7.8366,   6.4877,   5.5242],\n",
      "          [ 10.5773,  11.4551,   5.7597,  ...,   7.0230,   6.4234,   5.0103]],\n",
      "\n",
      "         [[  7.6225,   4.6677,   3.1261,  ...,   7.6225,   5.9310,   3.9397],\n",
      "          [  7.7938,   4.4536,   2.1840,  ...,   8.0293,   3.3616,   0.0428],\n",
      "          [  6.8731,   9.3782,   3.8112,  ...,   4.6677,  -0.3426,   0.2355],\n",
      "          ...,\n",
      "          [  3.9611,  -0.7708,   6.1665,  ...,   5.0317,   3.5329,   2.4195],\n",
      "          [  4.9889,   3.2760,   9.6352,  ...,   3.4687,   3.3830,   3.2117],\n",
      "          [  7.4726,   1.4988,   3.2760,  ...,   2.2482,   4.6463,   2.1626]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  4.8390,   3.4472,   7.5583,  ...,   4.2181,   2.6336,   4.2395],\n",
      "          [  6.9159,   7.1728,   7.1514,  ...,  -0.5995,   3.9611,   8.2648],\n",
      "          [  6.7660,   9.4639,   3.4472,  ...,   3.7256,   5.4599,  12.3116],\n",
      "          ...,\n",
      "          [  6.7232,   8.2862,   2.7407,  ...,   1.9699,   2.0127,   3.2974],\n",
      "          [  5.2886,   5.7383,  -2.3339,  ...,  -1.0706,   0.0642,   4.6677],\n",
      "          [  2.2268,   5.0531,   2.2268,  ...,   4.2395,   4.1752,   3.8327]],\n",
      "\n",
      "         [[  2.4623,   5.0103,   3.9397,  ...,  -0.5567,   5.8667,   4.3894],\n",
      "          [  2.2910,   6.8945,   4.3251,  ...,   0.8350,   4.4964,   5.7169],\n",
      "          [  9.8279,  11.2624,  11.5194,  ...,   4.4750,   1.3061,   7.7724],\n",
      "          ...,\n",
      "          [  1.3275,   2.6336,   3.8112,  ...,   2.8691,   2.3124,   5.9096],\n",
      "          [  3.2974,   8.7359,   9.9349,  ...,   0.9421,  -0.9849,   5.7811],\n",
      "          [  5.9738,   6.8731,   8.4361,  ...,   4.9675,   5.4599,   7.0872]],\n",
      "\n",
      "         [[ -5.4385,  -7.2371,  -7.1514,  ...,  -5.6312,  -6.6804,  -4.3679],\n",
      "          [ -8.9500, -12.1831, -10.4274,  ...,  -8.4789, -10.1276,  -6.9159],\n",
      "          [-10.0206, -13.6177, -10.3846,  ...,  -9.1213, -10.7486,  -7.4084],\n",
      "          ...,\n",
      "          [ -7.8580, -10.6629,  -9.5495,  ...,  -7.8794,  -8.5218,  -5.3743],\n",
      "          [ -8.7359, -11.1126,  -9.2069,  ...,  -7.9437,  -9.6994,  -6.2522],\n",
      "          [ -5.9096,  -7.5154,  -6.3164,  ...,  -5.1602,  -6.5947,  -4.5178]]],\n",
      "\n",
      "\n",
      "        [[[ -4.1967,  -6.7446,  -6.2093,  ...,  -7.6867,  -7.6225,  -4.8176],\n",
      "          [ -6.4449, -10.2989,  -9.5709,  ..., -10.4702, -10.8770,  -7.1086],\n",
      "          [ -6.7018, -10.0420,  -9.0999,  ...,  -9.4853,  -9.9777,  -6.8731],\n",
      "          ...,\n",
      "          [ -7.5797, -10.9627,  -8.9072,  ...,  -8.3077,  -8.1578,  -5.6955],\n",
      "          [ -7.1514, -10.8984, -10.2133,  ...,  -8.7145,  -7.4726,  -4.9246],\n",
      "          [ -4.2609,  -6.8731,  -6.7446,  ...,  -5.2030,  -4.1967,  -2.8691]],\n",
      "\n",
      "         [[  7.3441,  12.3116,   9.2926,  ...,   6.2307,  11.2838,   4.8390],\n",
      "          [  6.2950,  11.0269,   7.2157,  ...,   1.7129,   8.8644,  10.8556],\n",
      "          [  4.8604,   4.4536,   5.8453,  ...,   4.9675,   5.7383,   8.5218],\n",
      "          ...,\n",
      "          [  4.5178,   6.2307,   5.8025,  ...,   8.3291,   9.2498,   6.0809],\n",
      "          [  4.5821,   8.1578,   8.4575,  ...,   7.8580,   5.2030,   4.2395],\n",
      "          [  3.5971,   8.5432,  10.4916,  ...,   5.1816,   1.7986,   3.0404]],\n",
      "\n",
      "         [[  6.4234,   7.0230,   5.9310,  ...,   3.9611,   6.2950,   5.7597],\n",
      "          [  3.3188,   0.8993,   0.6209,  ...,  -1.9699,   0.6852,   2.4837],\n",
      "          [  3.7470,  -0.7922,   1.4560,  ...,   0.7708,   1.6487,   1.6487],\n",
      "          ...,\n",
      "          [  9.9777,   8.2648,   3.4687,  ...,   1.9484,   3.1261,   2.9976],\n",
      "          [  6.3378,  10.3417,   2.3767,  ...,   6.5091,   5.1388,   3.3402],\n",
      "          [  2.6550,   7.7295,   6.7018,  ...,   4.6677,   2.3124,   0.0856]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  2.6978,   2.0341,   2.7621,  ...,   3.3830,  -0.8993,   1.5416],\n",
      "          [  4.0254,   2.6764,   5.6740,  ...,   5.6312,   1.7557,   2.2910],\n",
      "          [  4.5606,   9.1641,   8.8644,  ...,   1.8628,   5.8453,   6.1879],\n",
      "          ...,\n",
      "          [  2.3553,  -3.2760,  -1.6701,  ...,  -0.1285,  -1.4988,   3.9183],\n",
      "          [  5.4813,   2.4195,   3.9611,  ...,  -3.4258,  -0.5567,   3.7470],\n",
      "          [  3.7898,   3.2545,   4.2609,  ...,  -0.7922,   0.4711,   3.2760]],\n",
      "\n",
      "         [[  3.1903,   4.8818,   3.9825,  ...,   7.5368,   6.0380,   6.2093],\n",
      "          [  1.5202,   0.5781,   2.0769,  ...,   5.1173,   2.9120,   5.7169],\n",
      "          [  0.7494,   2.6764,   3.0190,  ...,   2.1840,   0.2141,   4.9461],\n",
      "          ...,\n",
      "          [ 11.5622,   5.2886,  -2.3339,  ...,  -1.2847,  -0.0214,   6.0166],\n",
      "          [ 12.6970,   3.6828,   0.1713,  ...,  -0.8779,   1.1134,   6.5733],\n",
      "          [  8.9500,   2.4837,   1.6059,  ...,   0.8779,   2.5694,   4.2181]],\n",
      "\n",
      "         [[ -5.1816,  -6.8945,  -6.8517,  ...,  -7.9008,  -7.8580,  -4.1967],\n",
      "          [ -7.2585,  -9.6352,  -9.5281,  ..., -10.0848, -10.5344,  -6.1451],\n",
      "          [ -7.1300,  -9.2498,  -9.2712,  ...,  -9.0142,  -9.4639,  -5.9310],\n",
      "          ...,\n",
      "          [ -8.3719, -10.1705,  -8.2434,  ...,  -7.4940,  -7.2799,  -4.8390],\n",
      "          [ -8.1364, -10.7700, -10.4274,  ...,  -7.4512,  -6.5947,  -4.4750],\n",
      "          [ -4.9889,  -7.0444,  -7.3870,  ...,  -4.3251,  -3.8969,  -2.9334]]],\n",
      "\n",
      "\n",
      "        [[[ -4.6035,  -7.4940,  -7.0872,  ...,  -7.8794,  -7.9865,  -5.6312],\n",
      "          [ -6.7018, -10.5344,  -9.2498,  ...,  -9.9777, -10.5773,  -7.6225],\n",
      "          [ -6.9801, -10.3203,  -7.9651,  ...,  -9.6566, -11.1126,  -7.9008],\n",
      "          ...,\n",
      "          [ -6.3592,  -9.8493,  -8.7573,  ..., -10.2989, -11.5836,  -8.4789],\n",
      "          [ -6.5733,  -9.9777,  -9.1427,  ..., -10.8342, -11.3481,  -7.9865],\n",
      "          [ -4.0896,  -6.2093,  -5.7169,  ...,  -7.0658,  -7.1514,  -5.0745]],\n",
      "\n",
      "         [[  6.6804,   9.9777,  10.5773,  ...,   7.8152,  10.4274,   5.8239],\n",
      "          [  3.5115,   2.9120,   5.3100,  ...,   4.4750,   7.6653,   9.6994],\n",
      "          [  2.2910,  -1.8414,   1.6915,  ...,   1.7986,   0.2141,   5.6312],\n",
      "          ...,\n",
      "          [  7.0872,   5.8453,   5.2886,  ...,  10.1919,   6.8945,   6.7232],\n",
      "          [  5.1816,   4.9246,   6.0594,  ...,   9.0142,   5.3315,   6.4020],\n",
      "          [  5.2030,   5.3529,   6.6161,  ...,   2.9120,   4.7962,   6.0594]],\n",
      "\n",
      "         [[  5.0959,   8.6931,   6.5091,  ...,   5.8882,   6.9373,   5.8025],\n",
      "          [  2.6122,   1.1562,  -2.5694,  ...,   2.0769,   2.1626,   1.3489],\n",
      "          [  4.4750,   0.9635,   1.8200,  ...,   6.5733,   2.9762,   0.3854],\n",
      "          ...,\n",
      "          [  5.7811,   3.1261,   1.3275,  ...,   3.6614,   5.5884,   4.1538],\n",
      "          [  5.5028,   1.6273,   2.9548,  ...,   5.7597,   3.6400,   3.4472],\n",
      "          [  4.6891,   4.0039,   4.4964,  ...,   3.8327,   1.8628,   1.2205]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  5.4171,   3.9183,   4.4108,  ...,   4.3251,   3.2974,   4.2823],\n",
      "          [  9.7636,   7.0444,   8.3933,  ...,   4.5821,   5.6955,   4.0468],\n",
      "          [  7.7510,   4.3894,   5.1173,  ...,   2.7407,   7.0016,   3.2117],\n",
      "          ...,\n",
      "          [  4.2395,   0.0856,   1.1134,  ...,   0.9421,  -3.9183,   4.6249],\n",
      "          [  4.4750,   3.1047,   2.4837,  ...,   0.6209,   0.0000,   6.3164],\n",
      "          [  1.8842,   4.4322,   5.2458,  ...,   5.5028,   6.2950,   6.4877]],\n",
      "\n",
      "         [[  1.9270,   6.0594,   5.3743,  ...,   5.6098,   4.8390,   4.4964],\n",
      "          [  0.6852,  -0.1927,   0.8136,  ...,   3.5757,   4.4322,   2.9120],\n",
      "          [  2.0555,   1.1348,   1.1990,  ...,   2.0555,   6.7660,   6.9587],\n",
      "          ...,\n",
      "          [  4.8818,   3.1261,   1.2205,  ...,   2.7621,   0.5139,   6.6804],\n",
      "          [  3.8112,   1.8200,   1.9270,  ...,   4.9675,   4.0254,   9.8493],\n",
      "          [  5.5670,   2.8905,   4.7962,  ...,   5.7597,   6.8731,   6.3378]],\n",
      "\n",
      "         [[ -5.2030,  -7.4940,  -7.0016,  ...,  -8.2006,  -8.3077,  -4.9032],\n",
      "          [ -7.0016,  -9.6994,  -8.7145,  ...,  -9.7636, -10.7272,  -6.7232],\n",
      "          [ -6.9801,  -9.2712,  -7.5797,  ...,  -8.6931, -10.3632,  -6.9159],\n",
      "          ...,\n",
      "          [ -6.9159,  -8.9286,  -8.5004,  ...,  -9.6994, -10.5559,  -7.1086],\n",
      "          [ -7.1300,  -9.3568,  -9.2712,  ..., -10.0420, -10.7057,  -7.2157],\n",
      "          [ -4.6035,  -6.0166,  -5.8667,  ...,  -6.9373,  -7.3870,  -4.9461]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -5.5028,  -8.1578,  -7.1300,  ..., -10.5344,  -9.4211,  -5.9096],\n",
      "          [ -7.1943, -10.6201,  -9.5923,  ..., -13.7462, -12.5685,  -8.0293],\n",
      "          [ -6.3378,  -9.4639,  -8.4147,  ..., -11.8191, -11.0483,  -7.4940],\n",
      "          ...,\n",
      "          [ -5.9310,  -8.5432,  -6.8517,  ...,  -7.6653,  -8.2862,  -5.5028],\n",
      "          [ -6.4020,  -9.4639,  -8.5218,  ...,  -9.3140,  -9.4425,  -6.4020],\n",
      "          [ -4.1967,  -6.6590,  -6.5733,  ...,  -5.9096,  -5.8882,  -4.0682]],\n",
      "\n",
      "         [[  4.0039,   7.3655,   8.7573,  ...,   7.8152,   7.1514,   4.4108],\n",
      "          [  6.0809,   6.4663,   7.1728,  ...,   6.0380,   8.3077,   5.6098],\n",
      "          [  6.2950,   7.3870,   3.5329,  ...,   6.2307,   2.8477,   5.0745],\n",
      "          ...,\n",
      "          [  4.4322,   4.1752,   3.8327,  ...,   3.7898,   7.4940,   7.0872],\n",
      "          [  7.2371,  10.4702,   5.8882,  ...,   8.4575,   4.6249,   6.1451],\n",
      "          [  5.2458,   7.1086,   7.1300,  ...,  12.3758,  11.5408,   7.7724]],\n",
      "\n",
      "         [[  6.4234,   7.3441,   7.7510,  ...,   3.5543,   7.2799,   8.6931],\n",
      "          [  2.8477,   4.3251,   4.5606,  ...,   5.2886,   5.9952,   8.3077],\n",
      "          [  3.6185,   6.0809,   4.9461,  ...,   4.3251,   4.1110,   5.5884],\n",
      "          ...,\n",
      "          [  4.7105,   5.3957,   3.8969,  ...,  -2.5480,  -0.9849,   4.2181],\n",
      "          [  8.0507,   9.3568,   9.7850,  ...,   1.6273,  -0.1713,   0.6423],\n",
      "          [  5.5456,   5.3529,   7.2585,  ...,   7.3227,   1.5202,  -0.5781]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  5.7811,   5.9952,   2.5051,  ...,   4.4964,   4.6249,   5.4385],\n",
      "          [  5.7383,   6.6161,   0.1499,  ...,  10.8128,   8.2006,   4.8604],\n",
      "          [  5.7811,   2.0555,  -1.2419,  ...,   7.2157,   6.7874,   2.6122],\n",
      "          ...,\n",
      "          [  0.9207,   4.7105,  -0.7708,  ...,   2.2268,   2.4623,  -0.3854],\n",
      "          [  2.1840,   4.7962,  -0.1713,  ...,  -4.2181,  -3.2545,  -1.1990],\n",
      "          [  4.4322,   0.4068,   2.3553,  ...,   0.5995,  -0.6423,   5.4599]],\n",
      "\n",
      "         [[  1.8628,   5.9096,   8.8858,  ...,   5.3315,   4.7962,   8.8001],\n",
      "          [  2.5266,   4.3465,   5.1602,  ...,   9.3140,   7.8794,   8.7787],\n",
      "          [  4.8176,   4.3679,   3.5757,  ...,   6.2950,   5.5028,   6.5947],\n",
      "          ...,\n",
      "          [  4.3037,   7.2585,   6.0594,  ...,   3.5115,   2.7193,   3.9611],\n",
      "          [  2.8477,   5.9952,  12.0761,  ...,   8.5218,   4.0682,   3.5115],\n",
      "          [  1.9913,   3.3616,   6.4234,  ...,  11.8405,   9.4425,   7.3441]],\n",
      "\n",
      "         [[ -6.0166,  -8.3505,  -7.3655,  ..., -10.0634,  -9.0356,  -5.3529],\n",
      "          [ -7.9008, -10.6629,  -9.6780,  ..., -12.6542, -11.7763,  -7.1514],\n",
      "          [ -7.0444,  -9.2069,  -8.5860,  ..., -10.7057, -10.7914,  -6.9801],\n",
      "          ...,\n",
      "          [ -6.3592,  -8.2648,  -6.6804,  ...,  -7.6225,  -8.0935,  -4.8390],\n",
      "          [ -7.0658,  -9.2712,  -8.5218,  ...,  -9.2283,  -9.1427,  -5.5242],\n",
      "          [ -4.9246,  -6.8517,  -6.9159,  ...,  -6.0380,  -6.1237,  -3.9397]]],\n",
      "\n",
      "\n",
      "        [[[ -4.0039,  -7.3227,  -7.1514,  ...,  -8.1150,  -7.7295,  -5.1173],\n",
      "          [ -5.8882, -10.7057, -10.3203,  ..., -11.4337, -11.1768,  -7.6653],\n",
      "          [ -5.0531,  -9.4853,  -9.3568,  ..., -11.2624, -11.2838,  -7.8580],\n",
      "          ...,\n",
      "          [ -5.0531,  -9.4211,  -8.3719,  ...,  -6.4020,  -8.1578,  -6.2522],\n",
      "          [ -5.5884, -10.4274, -10.2347,  ...,  -7.9222,  -9.1427,  -6.8303],\n",
      "          [ -3.2331,  -6.4234,  -6.4877,  ...,  -5.3529,  -6.0166,  -4.5392]],\n",
      "\n",
      "         [[  9.9992,   9.2712,   6.3378,  ...,   4.1752,   7.8366,   5.5670],\n",
      "          [  8.2434,   7.7510,   3.5971,  ...,   5.5670,   2.5480,   6.5947],\n",
      "          [  6.8303,   6.8517,   3.7898,  ...,   6.4877,   1.9913,   3.0404],\n",
      "          ...,\n",
      "          [  8.7787,   5.1388,   0.2783,  ...,   3.1903,   3.8969,   5.1388],\n",
      "          [  6.9373,   7.7938,   6.1237,  ...,   5.1816,   5.8882,   6.0166],\n",
      "          [  6.3378,   7.6225,   5.9524,  ...,   4.0896,   5.0531,   5.2886]],\n",
      "\n",
      "         [[  5.8882,   6.8945,   9.5923,  ...,  -0.6423,   5.2244,   5.0317],\n",
      "          [  4.5392,   7.0444,  13.0610,  ...,  -3.4044,  -1.8414,   0.6852],\n",
      "          [  7.1728,   4.4322,   5.1602,  ...,   3.1261,   2.4623,   1.9056],\n",
      "          ...,\n",
      "          [  7.0872,   5.4385,   6.6376,  ...,   0.4496,   2.1197,   1.0706],\n",
      "          [  6.4449,   5.2030,   5.1816,  ...,   4.5178,   5.1602,   3.0833],\n",
      "          [  4.2823,   5.3743,   4.5392,  ...,   3.5329,   3.1903,   1.2633]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  2.6122,   2.5266,   1.0706,  ...,   7.2371,   4.9032,   0.3212],\n",
      "          [  4.1538,   5.2030,   5.9310,  ...,   8.1150,   9.2926,   1.6915],\n",
      "          [  4.1538,   3.0618,   9.6566,  ...,   1.2419,   3.3830,   5.0103],\n",
      "          ...,\n",
      "          [  2.8691,   5.2458,   5.8667,  ...,   3.8755,   3.8755,   5.2244],\n",
      "          [  3.1903,   3.8541,   6.4234,  ...,   1.5416,   3.5971,   4.6035],\n",
      "          [  3.8755,   4.1110,   7.0444,  ...,   4.2395,   4.8604,   3.0833]],\n",
      "\n",
      "         [[  3.4472,   4.1110,   2.0983,  ...,   1.4132,   6.1665,   4.9246],\n",
      "          [  3.0833,   3.8541,  10.3203,  ...,   2.1411,   5.4171,   4.9461],\n",
      "          [ -0.6423,   1.3703,  10.8556,  ...,   1.7557,   1.4560,   5.1602],\n",
      "          ...,\n",
      "          [  1.4560,   2.6978,   7.7510,  ...,   0.6852,   1.8842,   5.0103],\n",
      "          [ -1.1562,  -0.7494,   6.4020,  ...,   1.3275,   2.3553,   4.8176],\n",
      "          [  2.6764,   0.8565,   5.8882,  ...,   3.7042,   3.8327,   4.0254]],\n",
      "\n",
      "         [[ -5.0103,  -7.6439,  -7.3870,  ...,  -7.2585,  -7.6011,  -4.3251],\n",
      "          [ -6.5733, -10.1705, -10.1276,  ..., -10.2989, -10.9199,  -6.5947],\n",
      "          [ -5.6526,  -9.0356,  -9.5495,  ...,  -9.9349, -10.4060,  -6.3164],\n",
      "          ...,\n",
      "          [ -5.5670,  -8.7359,  -8.0293,  ...,  -6.2522,  -8.0507,  -5.2886],\n",
      "          [ -6.3592,  -9.9777,  -9.8707,  ...,  -7.7081,  -8.9286,  -5.8025],\n",
      "          [ -4.1324,  -6.4449,  -6.4877,  ...,  -5.4599,  -6.1451,  -4.1110]]],\n",
      "\n",
      "\n",
      "        [[[ -4.0254,  -6.8089,  -7.3013,  ...,  -6.5733,  -6.4020,  -4.7319],\n",
      "          [ -6.1023, -10.4060, -10.8556,  ...,  -9.2283,  -8.8644,  -6.5519],\n",
      "          [ -5.9524, -10.3632, -10.7700,  ...,  -9.9777,  -9.4425,  -6.5947],\n",
      "          ...,\n",
      "          [ -6.7660, -10.2775, -10.5987,  ...,  -8.0507,  -7.9008,  -5.5456],\n",
      "          [ -5.5670,  -9.6780, -10.3846,  ...,  -8.4575,  -8.3291,  -5.8239],\n",
      "          [ -2.6978,  -5.4171,  -6.2307,  ...,  -5.2458,  -5.0745,  -3.7042]],\n",
      "\n",
      "         [[  2.4837,   4.3465,   4.5392,  ...,   4.5178,   6.3164,   2.5480],\n",
      "          [  0.5781,   2.9976,   4.6463,  ...,   5.3100,   7.0872,   5.7383],\n",
      "          [ -0.1285,   2.4837,   2.0983,  ...,   2.9976,   3.9825,   3.8112],\n",
      "          ...,\n",
      "          [  3.1047,   5.4813,   4.6463,  ...,   3.9397,   5.2886,   2.2482],\n",
      "          [  4.7748,   4.9675,   1.4774,  ...,   6.3378,   6.1023,   4.6463],\n",
      "          [  4.7319,   3.6185,   1.3703,  ...,   5.6312,   5.5456,   3.9397]],\n",
      "\n",
      "         [[  4.4750,   4.7105,   4.9889,  ...,   3.0404,   5.5242,   4.8604],\n",
      "          [  3.0404,   2.4623,  -0.1927,  ...,   3.2974,   3.8755,   0.7922],\n",
      "          [  4.6677,   2.6764,  -0.2569,  ...,   7.9865,   7.1086,   1.3275],\n",
      "          ...,\n",
      "          [  0.2998,   4.0468,   4.8176,  ...,   5.2030,   6.4877,   3.0404],\n",
      "          [ -1.5416,  -0.8136,   2.3553,  ...,   6.2736,   4.7962,   3.2974],\n",
      "          [  2.6764,   2.1197,   2.1411,  ...,   5.7811,   3.8755,   0.7494]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  4.4322,   5.5028,   7.3870,  ...,   4.3465,   4.0468,   4.3894],\n",
      "          [  2.4195,   2.6550,   9.5067,  ...,   6.5305,   4.9889,   6.5519],\n",
      "          [  4.3465,   3.2545,   8.9500,  ...,   6.5733,   3.8755,   6.5091],\n",
      "          ...,\n",
      "          [  6.9159,   8.1364,   5.1816,  ...,  -1.1348,   0.5995,   4.1110],\n",
      "          [  0.8565,   5.9096,   7.4726,  ...,   0.2569,   5.8667,   7.2371],\n",
      "          [ -0.8136,   3.4687,   6.8089,  ...,  -0.6852,   5.3100,   6.2093]],\n",
      "\n",
      "         [[  2.8691,   4.6891,   9.5495,  ...,   2.8905,   6.2307,   6.8517],\n",
      "          [  1.1990,  -1.0706,   3.0833,  ...,  -0.7494,   3.3830,   6.2093],\n",
      "          [  4.4750,   1.1990,   3.1689,  ...,   4.5606,   4.8390,   7.6439],\n",
      "          ...,\n",
      "          [ 10.6843,   9.2069,   1.8842,  ...,   8.2220,   4.0039,   5.4813],\n",
      "          [  5.9310,   7.2371,   7.0658,  ...,   5.1173,   2.9334,   6.2950],\n",
      "          [  2.5266,   3.0618,   8.3077,  ...,   4.6249,   3.7684,   4.9461]],\n",
      "\n",
      "         [[ -4.3894,  -6.5091,  -7.5154,  ...,  -6.9587,  -6.6376,  -4.1324],\n",
      "          [ -6.2736,  -9.6994, -10.7914,  ...,  -9.4211,  -8.9286,  -5.7811],\n",
      "          [ -6.1879,  -9.8279, -10.5987,  ...,  -9.5923,  -9.0999,  -5.8239],\n",
      "          ...,\n",
      "          [ -7.5154, -10.3846, -10.9627,  ...,  -7.5368,  -7.5583,  -5.0317],\n",
      "          [ -6.3378,  -9.3782, -10.2989,  ...,  -7.9437,  -8.2220,  -5.6098],\n",
      "          [ -3.1047,  -5.2030,  -6.2950,  ...,  -4.7748,  -5.2244,  -3.7684]]]],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "conv_int.bias = model.features[17].bias\n",
    "output_int = conv_int(act_int)\n",
    "output_recovered = output_int * (act_alpha / (2**act_bit-1)) * (w_alpha / (2**(w_bit-1)-1))\n",
    "print(output_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0054, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output_ref = save_output.outputs[6][0]\n",
    "diff = F.relu(output_recovered) - output_ref\n",
    "print(diff.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
